# MuTual Analysis with BERT and Data Augmentations

This repository contains an in-depth analysis of the MuTual paper, focusing on the BERT model. Our goal is to reproduce the results presented in the paper and further enhance them by introducing data augmentations.

## Dataset

You can obtain the dataset used in the MuTual paper by visiting the [MuTual: A Dataset for Multi-Turn Dialogue Reasoning](https://www.aclweb.org/anthology/2020.acl-main.130/) (ACL2020) page. Detailed dataset statistics are available on the MuTual [GitHub](https://github.com/Nealcly/MuTual/blob/master/README.md) page.

## Models

Our primary focus is on the BERT model for this analysis. You can find the BERT model and related resources on the [GitHub](https://github.com/google-research/bert) page.

We have also initiated work on implementing the GPT2 model, but please note that this work is currently a work in progress and not yet completed.
